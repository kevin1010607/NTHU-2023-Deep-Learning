{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25ab8dd3",
   "metadata": {},
   "source": [
    "# DL_comp4_全_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc3054f",
   "metadata": {},
   "source": [
    "## Member\n",
    "\n",
    "- 邱煒甯, 108072244\n",
    "- 劉祥暉, 109072142\n",
    "- 簡佩如, 112065525\n",
    "- 陳凱揚, 108032053"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda621b",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c635c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 20:36:23.066878: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9360] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-15 20:36:23.066929: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-15 20:36:23.066954: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1537] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-15 20:36:23.076403: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import copy\n",
    "import pickle\n",
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "\n",
    "from evaluation.environment import TrainingEnvironment, TestingEnvironment\n",
    "\n",
    "os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '0'\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6600fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Official hyperparameters for this competition (do not modify)\n",
    "N_TRAIN_USERS = 1000\n",
    "N_TEST_USERS = 2000\n",
    "N_ITEMS = 209527\n",
    "HORIZON = 2000\n",
    "\n",
    "EMBEDDING_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_EPISODES = 250\n",
    "TEST_EPISODES = 5\n",
    "TRAIN_RETRAIN = 400\n",
    "TEST_RETRAIN = 100\n",
    "SLATE_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77b22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "USER_DATA = os.path.join('dataset', 'user_data.json')\n",
    "ITEM_DATA = os.path.join('dataset', 'item_data.json')\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_PATH = os.path.join('output', 'output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0de23fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_json(USER_DATA, lines=True)\n",
    "# df_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb33f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item = pd.read_json(ITEM_DATA, lines=True)\n",
    "# df_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d58d9",
   "metadata": {},
   "source": [
    "## 2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2aea4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 5000\n",
    "REPEAT_TIME = 1\n",
    "MAX_DATA = 200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd8a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n",
      "123658\n",
      "123658\n"
     ]
    }
   ],
   "source": [
    "def dataset_generator(history, clicked):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((history, clicked))\n",
    "    dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "    dataset = dataset.repeat(REPEAT_TIME)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_history(history, clicked):\n",
    "    history_file = os.path.join('dataset', 'history.pkl')\n",
    "    clicked_file = os.path.join('dataset', 'clicked.pkl')\n",
    "    \n",
    "    if len(history) > MAX_DATA:\n",
    "        history = history[:6000] + history[-(MAX_DATA - 6000):]\n",
    "        clicked = clicked[:6000] + clicked[-(MAX_DATA - 6000):]\n",
    "    \n",
    "    with open(history_file, 'wb') as file:\n",
    "        pickle.dump(history, file)\n",
    "    with open(clicked_file, 'wb') as file:\n",
    "        pickle.dump(clicked, file)\n",
    "\n",
    "        \n",
    "def read_history():\n",
    "    user_history = [copy.deepcopy(h) for h in df_user['history']]\n",
    "    try:\n",
    "        history_file = os.path.join('dataset', 'history.pkl')\n",
    "        clicked_file = os.path.join('dataset', 'clicked.pkl')\n",
    "\n",
    "        with open(history_file, 'rb') as file:\n",
    "            history = pickle.load(file)\n",
    "        with open(clicked_file, 'rb') as file:\n",
    "            clicked = pickle.load(file)\n",
    "    except:\n",
    "        history = [(idx, i) for idx, row in enumerate(user_history) for i in row]\n",
    "        clicked = [1 for _ in range(len(history))]\n",
    "    \n",
    "    return user_history, history, clicked\n",
    "\n",
    "\n",
    "def save_csv(train_history):\n",
    "    with open('train_history1.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerows(train_history)\n",
    "    \n",
    "\n",
    "user_history, history, clicked = read_history()\n",
    "save_history(history, clicked)\n",
    "\n",
    "print(sum([len(i) for i in user_history]))\n",
    "print(len(history))\n",
    "print(len(clicked))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6574a4",
   "metadata": {},
   "source": [
    "## 3. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38059914",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunkSVDRecommender(tf.keras.Model):\n",
    "    '''\n",
    "    Simplified Funk-SVD recommender model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, m_users: int, n_items: int, embedding_size: int, learning_rate: float):\n",
    "        super().__init__()\n",
    "        self.m = m_users\n",
    "        self.n = n_items\n",
    "        self.k = embedding_size\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        # user embeddings P\n",
    "        self.P = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.m, self.k)))\n",
    "\n",
    "        # item embeddings Q\n",
    "        self.Q = tf.Variable(tf.keras.initializers.RandomNormal()(shape=(self.n, self.k)))\n",
    "        \n",
    "        # loss object\n",
    "        self.loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "\n",
    "        # optimizer\n",
    "        self.optimizer = tf.optimizers.Adam(learning_rate=self.lr)\n",
    "        \n",
    "        # checkpoint\n",
    "        self.checkpoint_path =\"/home/u6180060/DL/C4/ckpt\" #'./ckpt'\n",
    "        self.checkpoint = tf.train.Checkpoint(optimizer=self.optimizer, model=self)\n",
    "        self.checkpoint_manager = tf.train.CheckpointManager(self.checkpoint, self.checkpoint_path, max_to_keep=3)\n",
    "        \n",
    "    def save_checkpoint(self):\n",
    "        self.checkpoint_manager.save()\n",
    "\n",
    "    def restore_checkpoint(self):\n",
    "        # Restore the latest checkpoint\n",
    "        if self.checkpoint_manager.latest_checkpoint:\n",
    "            self.checkpoint.restore(self.checkpoint_manager.latest_checkpoint)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, user_ids: tf.Tensor, item_ids: tf.Tensor):\n",
    "        # dot product the user and item embeddings corresponding to the observed interaction pairs to produce predictions\n",
    "        raw_score = tf.reduce_sum(tf.gather(self.P, indices=user_ids) * tf.gather(self.Q, indices=item_ids), axis=1)\n",
    "        y_pred = tf.nn.sigmoid(raw_score)\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    @tf.function\n",
    "    def compute_loss(self, y_true: tf.Tensor, y_pred: tf.Tensor):\n",
    "        loss = self.loss_object(y_true, y_pred)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, data: tf.Tensor, label: tf.Tensor):\n",
    "        user_ids = tf.cast(data[:, 0], dtype=tf.int32)\n",
    "        item_ids = tf.cast(data[:, 1], dtype=tf.int32)\n",
    "        y_true = tf.cast(label, dtype=tf.float32)\n",
    "        \n",
    "        # compute loss\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(user_ids, item_ids)\n",
    "            loss = self.compute_loss(y_true, y_pred)\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "\n",
    "        # update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    @tf.function\n",
    "    def eval_predict_onestep(self, query: int):\n",
    "        # dot product the selected user and all item embeddings to produce predictions\n",
    "        user_id = tf.cast(query, tf.int32)\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, user_id) * self.Q, axis=1)\n",
    "        y_top = tf.math.top_k(y_pred, 10).indices\n",
    "        \n",
    "        return y_top\n",
    "    def eval_predict_onestep_test(self, query:int, train_history):\n",
    "        user_id = tf.cast(query, tf.int32)\n",
    "        y_pred = tf.reduce_sum(tf.gather(self.P, user_id) * self.Q, axis=1).numpy().tolist()\n",
    "        for i in train_history:\n",
    "            y_pred[i]=tf.float32.max\n",
    "        y_top = tf.math.top_k(y_pred, 10).indices\n",
    "        return y_top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1156e4b0",
   "metadata": {},
   "source": [
    "## 4. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9bfb4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_data(sorted_y_pred,train_history):\n",
    "    y_top_5 = []\n",
    "    \n",
    "    # select the top 5 items with highest scores in y_pred and not in the history\n",
    "    idx = 0\n",
    "    while idx < len(sorted_y_pred) and len(y_top_5) < 5:\n",
    "        if sorted_y_pred[idx] not in train_history:\n",
    "            y_top_5.append(sorted_y_pred[idx])\n",
    "        idx += 1\n",
    "    \n",
    "    # select the item in history if len(y_top_5) < 5\n",
    "    while len(y_top_5) < 5:\n",
    "        random_number = random.randint(0, 209526)\n",
    "        if random_number not in train_history and random_number not in y_top_5:\n",
    "            y_top_5.append(random_number)\n",
    "        \n",
    "    return y_top_5\n",
    "\n",
    "def get_top_5_train(sorted_y_pred, history):\n",
    "    y_top_5 = []\n",
    "    \n",
    "    # select the top 5 items with highest scores in y_pred and not in the history\n",
    "    idx = 0\n",
    "    while idx < len(sorted_y_pred) and len(y_top_5) < 5:\n",
    "        if sorted_y_pred[idx] not in history:\n",
    "            y_top_5.append(sorted_y_pred[idx])\n",
    "        idx += 1\n",
    "    \n",
    "    # select the item in history if len(y_top_5) < 5\n",
    "    if len(y_top_5) < 5:\n",
    "        y_top_5 += history[:5 - len(y_top_5)]\n",
    "        \n",
    "    return y_top_5\n",
    "\n",
    "def get_top_5_test(sorted_y_pred, train_history, test_history):\n",
    "    y_top_5 = []\n",
    "    \n",
    "    # select the top 5 items with highest scores in y_pred and not in the history\n",
    "    idx = 0\n",
    "    while idx < len(sorted_y_pred) and len(y_top_5) < 5:\n",
    "        if sorted_y_pred[idx] not in test_history and sorted_y_pred[idx] in train_history:\n",
    "            y_top_5.append(sorted_y_pred[idx])\n",
    "        idx += 1\n",
    "    \n",
    "    idx = 0\n",
    "    while idx < len(sorted_y_pred) and len(y_top_5) < 5:\n",
    "        if sorted_y_pred[idx] not in test_history and sorted_y_pred[idx] not in y_top_5:\n",
    "            y_top_5.append(sorted_y_pred[idx])\n",
    "        idx += 1\n",
    "    \n",
    "    # select the item in history if len(y_top_5) < 5\n",
    "    if len(y_top_5) < 5:\n",
    "        y_top_5 += test_history[:5 - len(y_top_5)]\n",
    "        \n",
    "    return y_top_5\n",
    "\n",
    "def update_history(y_top_5, clicked_id, user_id, user_history, history, clicked):\n",
    "    if clicked_id in y_top_5:\n",
    "        if clicked_id in user_history[user_id]:\n",
    "            user_history[user_id].append(clicked_id)\n",
    "        for _ in range(2):\n",
    "            history.append((user_id, clicked_id))\n",
    "            clicked.append(1)\n",
    "    else:\n",
    "        for y in y_top_5:\n",
    "            history.append((user_id, y))\n",
    "            clicked.append(0)\n",
    "    \n",
    "    return user_history, history, clicked\n",
    "\n",
    "        \n",
    "def retrain(model, history, clicked):\n",
    "    dataset = dataset_generator(history, clicked)\n",
    "    \n",
    "    train_loss = []\n",
    "\n",
    "    # training\n",
    "    for (data, label) in dataset:\n",
    "        loss = recommend_model.train_step(data, label)\n",
    "        train_loss.append(loss.numpy())\n",
    "\n",
    "    # print losses\n",
    "    # print(f'Retrain_loss: {avg_train_loss:.4f}')\n",
    "\n",
    "\n",
    "recommend_model = FunkSVDRecommender(N_TEST_USERS, N_ITEMS, EMBEDDING_SIZE, LEARNING_RATE)\n",
    "recommend_model.restore_checkpoint()\n",
    "# retrain(recommend_model, history, clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f560ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is still some active users in the training environment.\n",
      "The current user is user 500.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-15 20:36:57.704604: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5602ab91d830 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-15 20:36:57.704667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2024-01-15 20:36:57.740709: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8906\n",
      "2024-01-15 20:36:57.799189: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The click result of recommending [105680, 147868, 38295, 80453, 95466] to user 500 is item 105680.\n",
      "User 500 is still in the environment.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the training environment\n",
    "train_env = TrainingEnvironment()\n",
    "\n",
    "# Reset the training environment (this can be useful when you have finished one episode of simulation and do not want to re-initialize a new environment)\n",
    "train_env.reset()\n",
    "\n",
    "# Check if there exist any active users in the environment\n",
    "env_has_next_state = train_env.has_next_state()\n",
    "print(f'There is {\"still some\" if env_has_next_state else \"no\"} active users in the training environment.')\n",
    "\n",
    "# Get the current user ID\n",
    "user_id = train_env.get_state()\n",
    "print(f'The current user is user {user_id}.')\n",
    "\n",
    "# Get the response of recommending the slate to the current user\n",
    "sorted_y_pred = recommend_model.eval_predict_onestep(user_id).numpy()\n",
    "slate = get_top_5_train(sorted_y_pred, user_history[user_id])\n",
    "clicked_id, in_environment = train_env.get_response(slate)\n",
    "print(f'The click result of recommending {slate} to user {user_id} is {f\"item {clicked_id}\" if clicked_id != -1 else f\"{clicked_id} (no click)\"}.')\n",
    "print(f'User {user_id} {\"is still in\" if in_environment else \"leaves\"} the environment.')\n",
    "\n",
    "# Get the normalized session length score of all users\n",
    "train_score = train_env.get_score()\n",
    "df_train_score = pd.DataFrame([[user_id, score] for user_id, score in enumerate(train_score)], columns=['user_id', 'avg_score'])\n",
    "# df_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8be62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5104it [00:07, 671.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5100it [00:07, 676.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 score: 0.997450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5123it [00:07, 672.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5123it [00:07, 663.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5140it [00:07, 656.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 score: 0.997430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5102it [00:07, 678.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 score: 0.997449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5096it [00:07, 691.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 score: 0.997452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5104it [00:07, 666.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5111it [00:07, 670.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:07, 659.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:07, 677.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5140it [00:08, 635.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 score: 0.997430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5138it [00:08, 642.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 score: 0.997431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5112it [00:07, 670.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 score: 0.997444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5139it [00:07, 663.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 score: 0.997430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5140it [00:07, 648.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 score: 0.997430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5129it [00:07, 657.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 score: 0.997436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5127it [00:07, 666.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5130it [00:07, 658.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5121it [00:07, 672.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5099it [00:07, 678.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 score: 0.997451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5121it [00:07, 662.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5117it [00:07, 667.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5121it [00:07, 669.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5112it [00:07, 673.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 score: 0.997444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5130it [00:07, 651.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5110it [00:07, 674.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5124it [00:08, 585.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 score: 0.997438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5114it [00:07, 674.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 score: 0.997443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:07, 667.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5124it [00:07, 670.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 score: 0.997438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5130it [00:07, 660.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5136it [00:07, 665.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 score: 0.997432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5123it [00:07, 662.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:07, 662.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5098it [00:07, 649.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 score: 0.997451\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5122it [00:08, 622.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5110it [00:08, 594.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5125it [00:08, 635.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5131it [00:08, 633.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5105it [00:08, 635.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5121it [00:08, 635.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5105it [00:07, 643.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5116it [00:08, 637.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 score: 0.997442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5131it [00:08, 619.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5139it [00:08, 622.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 score: 0.997430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5102it [00:08, 632.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 score: 0.997449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5121it [00:08, 626.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5131it [00:07, 644.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:08, 623.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:08, 622.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5132it [00:08, 629.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 score: 0.997434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:08, 632.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:07, 639.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5125it [00:08, 635.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5145it [00:08, 621.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 score: 0.997428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5127it [00:08, 629.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:08, 624.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5141it [00:08, 626.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 score: 0.997430\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5146it [00:08, 627.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 score: 0.997427\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5112it [00:08, 634.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 score: 0.997444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5133it [00:08, 626.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 score: 0.997434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5127it [00:08, 615.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5114it [00:08, 633.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 score: 0.997443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5096it [00:08, 635.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 score: 0.997452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:08, 614.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:08, 631.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5107it [00:08, 635.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 score: 0.997447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5122it [00:08, 626.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5137it [00:08, 621.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 score: 0.997432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5150it [00:08, 603.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 score: 0.997425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:08, 627.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5131it [00:08, 615.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5144it [00:08, 618.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 score: 0.997428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5134it [00:08, 624.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5107it [00:08, 631.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 score: 0.997447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5152it [00:08, 623.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 score: 0.997424\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5114it [00:07, 643.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 score: 0.997443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5108it [00:07, 657.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 score: 0.997446\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5129it [00:07, 657.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 score: 0.997436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5122it [00:07, 662.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:07, 655.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5115it [00:07, 668.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 score: 0.997443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5120it [00:07, 662.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5107it [00:07, 669.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 score: 0.997447\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5148it [00:07, 651.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 score: 0.997426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5123it [00:07, 670.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5104it [00:07, 668.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5111it [00:07, 661.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5143it [00:07, 644.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 score: 0.997428\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5097it [00:07, 672.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 score: 0.997452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5154it [00:08, 643.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 score: 0.997423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5136it [00:07, 653.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 score: 0.997432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5124it [00:07, 661.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 score: 0.997438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5124it [00:07, 657.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 score: 0.997438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5123it [00:07, 664.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5127it [00:07, 651.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5108it [00:07, 660.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 score: 0.997446\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5129it [00:07, 657.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 score: 0.997436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5126it [00:07, 651.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5133it [00:07, 659.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 score: 0.997434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:07, 662.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5118it [00:07, 667.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5132it [00:07, 660.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103 score: 0.997434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5122it [00:07, 653.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5101it [00:07, 669.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105 score: 0.997450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5111it [00:07, 658.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5129it [00:07, 661.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107 score: 0.997436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:07, 658.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5133it [00:07, 644.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109 score: 0.997434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5122it [00:07, 665.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5120it [00:07, 659.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5130it [00:07, 651.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5124it [00:07, 660.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113 score: 0.997438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:07, 649.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:07, 645.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5131it [00:07, 649.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5105it [00:07, 663.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5146it [00:07, 651.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118 score: 0.997427\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5137it [00:07, 646.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119 score: 0.997432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5097it [00:07, 663.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120 score: 0.997452\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:07, 658.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5124it [00:07, 657.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122 score: 0.997438\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5128it [00:07, 643.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123 score: 0.997436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5110it [00:07, 656.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5122it [00:07, 660.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5089it [00:07, 665.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126 score: 0.997456\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5134it [00:07, 653.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:07, 657.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5127it [00:07, 655.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5129it [00:07, 654.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130 score: 0.997436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5104it [00:07, 664.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5123it [00:07, 656.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132 score: 0.997439\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5132it [00:07, 648.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133 score: 0.997434\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5137it [00:07, 647.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134 score: 0.997432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5111it [00:07, 664.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5113it [00:07, 663.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136 score: 0.997444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5109it [00:07, 654.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5103it [00:07, 661.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138 score: 0.997449\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5125it [00:07, 658.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139 score: 0.997437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5113it [00:07, 653.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140 score: 0.997444\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5135it [00:07, 650.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141 score: 0.997433\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5117it [00:07, 656.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5115it [00:07, 664.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143 score: 0.997443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5138it [00:07, 649.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144 score: 0.997431\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5109it [00:07, 665.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145 score: 0.997445\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5120it [00:07, 648.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5093it [00:07, 671.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147 score: 0.997454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5169it [00:08, 640.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148 score: 0.997416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5120it [00:07, 660.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5180it [00:08, 629.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150 score: 0.997410\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5120it [00:07, 653.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5176it [00:08, 644.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152 score: 0.997412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5121it [00:07, 660.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 score: 0.997440\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5130it [00:07, 663.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154 score: 0.997435\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5117it [00:07, 656.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5114it [00:07, 648.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156 score: 0.997443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5105it [00:07, 667.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157 score: 0.997448\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5119it [00:07, 666.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158 score: 0.997441\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5094it [00:07, 653.48it/s]"
     ]
    }
   ],
   "source": [
    "train_history = [copy.deepcopy(h) for h in df_user['history']]\n",
    "\n",
    "# Initialize the training environment\n",
    "train_env = TrainingEnvironment()\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "\n",
    "# Repeat the training process for 5 times\n",
    "start_epoch = 0\n",
    "\n",
    "\n",
    "for epoch in range(start_epoch, 10000):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "    recommend_model.restore_checkpoint()\n",
    "    user_history, history, clicked = read_history()\n",
    "    retrain_cnt = 0\n",
    "\n",
    "    # Start the training process\n",
    "    with tqdm(desc='Training') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while train_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = train_env.get_state()\n",
    "\n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            # Here we provide a simple random implementation\n",
    "            sorted_y_pred = random.sample(range(0, 209527), 10)#recommend_model.eval_predict_onestep(cur_user).numpy()\n",
    "            slate = get_more_data(sorted_y_pred, train_history[cur_user])\n",
    "\n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = train_env.get_response(slate)\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "            if clicked_id != -1 and clicked_id not in train_history[cur_user]:\n",
    "                train_history[cur_user].append(clicked_id)\n",
    "                save_csv(train_history)\n",
    "            \n",
    "            user_history, history, clicked = update_history(slate, clicked_id, cur_user, user_history, history, clicked)\n",
    "            # Update retrain count\n",
    "            retrain_cnt += 1\n",
    "            if retrain_cnt == TRAIN_RETRAIN:\n",
    "                retrain_cnt = 0\n",
    "                retrain(recommend_model, history, clicked)\n",
    "            \n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "    \n",
    "    # Output the training score\n",
    "    train_score = train_env.get_score()\n",
    "    avg_scores = [np.average(score) for score in zip(*[train_score])]\n",
    "    result = (len(avg_scores) - sum(avg_scores)) / len(avg_scores)\n",
    "    print(f'Epoch {epoch} score: {result:.6f}\\n')\n",
    "    with open('traing_output.txt', 'a') as file:\n",
    "        file.write(f'Epoch {epoch} score: {result:.6f}\\n')\n",
    "    \n",
    "    # Reset the training environment\n",
    "    train_env.reset()\n",
    "    \n",
    "    # Save checkpoint\n",
    "    save_history(history, clicked)\n",
    "    recommend_model.save_checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b0be70",
   "metadata": {},
   "source": [
    "## 5. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d80dbd71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 14369it [39:54,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.996408\n",
      "\n",
      "Result: 0.996408\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1995</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1996</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1997</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1998</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1999</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  avg_score\n",
       "0           0     0.0025\n",
       "1           1     0.0045\n",
       "2           2     0.0050\n",
       "3           3     0.0050\n",
       "4           4     0.0050\n",
       "...       ...        ...\n",
       "1995     1995     0.0025\n",
       "1996     1996     0.0025\n",
       "1997     1997     0.0025\n",
       "1998     1998     0.0025\n",
       "1999     1999     0.0025\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the testing environment\n",
    "test_env = TestingEnvironment()\n",
    "scores = []\n",
    "\n",
    "# The item_ids here is for the random recommender\n",
    "item_ids = [i for i in range(N_ITEMS)]\n",
    "test_history = [copy.deepcopy(h) for h in df_user['history']]\n",
    "# Repeat the testing process for 5 times\n",
    "for _ in range(TEST_EPISODES):\n",
    "    # [TODO] Load your model weights here (in the beginning of each testing episode)\n",
    "    # [TODO] Code for loading your model weights...\n",
    "#     recommend_model.restore_checkpoint()\n",
    "    recommend_model.checkpoint.restore(\"/home/u6180060/DL/C4/ckpt/ckpt-250\")\n",
    "    test_history, history, clicked = read_history()\n",
    "    retrain_cnt = 0\n",
    "\n",
    "    # Start the testing process\n",
    "    with tqdm(desc='Testing') as pbar:\n",
    "        # Run as long as there exist some active users\n",
    "        while test_env.has_next_state():\n",
    "            # Get the current user id\n",
    "            cur_user = test_env.get_state()\n",
    "\n",
    "            # [TODO] Employ your recommendation policy to generate a slate of 5 distinct items\n",
    "            # [TODO] Code for generating the recommended slate...\n",
    "            # Here we provide a simple random implementation\n",
    "            sorted_y_pred = recommend_model.eval_predict_onestep_test(cur_user,train_history[cur_user]).numpy()\n",
    "            slate = get_top_5_train(sorted_y_pred, test_history[cur_user])\n",
    "\n",
    "            # Get the response of the slate from the environment\n",
    "            clicked_id, in_environment = test_env.get_response(slate)\n",
    "\n",
    "            # [TODO] Update your model here (optional)\n",
    "            # [TODO] You can update your model at each step, or perform a batched update after some interval\n",
    "            # [TODO] Code for updating your model...\n",
    "            if clicked_id != -1 and clicked_id not in train_history[cur_user]:\n",
    "                train_history[cur_user].append(clicked_id)\n",
    "            test_history, history, clicked = update_history(slate, clicked_id, cur_user, test_history, history, clicked)\n",
    "            \n",
    "            # Update retrain count\n",
    "            retrain_cnt += 1\n",
    "            if retrain_cnt == TEST_RETRAIN:\n",
    "                retrain_cnt = 0\n",
    "                retrain(recommend_model, history, clicked)\n",
    "            \n",
    "            # Update the progress indicator\n",
    "            pbar.update(1)\n",
    "\n",
    "    # Record the score of this testing episode\n",
    "    scores.append(test_env.get_score())\n",
    "    \n",
    "    # Output the testing score\n",
    "    test_score = test_env.get_score()\n",
    "    avg_scores = [np.average(score) for score in zip(*[test_score])]\n",
    "    result = (len(avg_scores) - sum(avg_scores)) / len(avg_scores)\n",
    "    print(f'Score: {result:.6f}\\n')\n",
    "    with open('testing_output.txt', 'a') as file:\n",
    "        file.write(f'Score: {result:.6f}\\n')\n",
    "\n",
    "    # Reset the testing environment\n",
    "    test_env.reset()\n",
    "\n",
    "    # [TODO] Delete or reset your model weights here (in the end of each testing episode)\n",
    "    # [TODO] Code for deleting your model weights...\n",
    "    test_history, history, clicked = None, None, None\n",
    "\n",
    "# Calculate the average scores \n",
    "avg_scores = [np.max(score) for score in zip(*scores)]\n",
    "result = (len(avg_scores) - sum(avg_scores)) / len(avg_scores)\n",
    "print(f'Result: {result:.6f}')\n",
    "\n",
    "# Generate a DataFrame to output the result in a .csv file\n",
    "df_result = pd.DataFrame([[user_id, avg_score] for user_id, avg_score in enumerate(avg_scores)], columns=['user_id', 'avg_score'])\n",
    "df_result.to_csv(OUTPUT_PATH, index=False)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65512c4c",
   "metadata": {},
   "source": [
    "## 6. Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea58f78b",
   "metadata": {},
   "source": [
    "### Models you have tried during the competition. Briefly describe the main idea of the model and the reason why you chose that model.\n",
    "\n",
    "- Content-based algorithms (item feature)\n",
    "\n",
    "    我們有嘗試將 item 的 headline, description 使用 bert 去產生 embedding, 並利用已經有的 user history 和從 training 環境中獲取的 interact data 去對每個 user 都 train 一個簡單的 linear model，用來找出最適合推薦給這個 user 的 item。\n",
    "\n",
    "- Collaborative filtering (Funk-SVD)\n",
    "\n",
    "    這邊是根據 tutorial 的範例修改而成，其中不一樣的地方在於我們會將曾經選擇過的 history 跳過不選擇，因為 user 去選看過的 item 的機率非常低，且會紀錄曾經點擊過的 item，再將來重新 train 的時候，會優先推薦這些 item 給 user。而這邊的 loss 是使用 `BinaryCrossEntropy`，最後我們採用這個 model。\n",
    "\n",
    "### List the experiments you have done. For instance, data collecting, utilizing the user / item datasets, hyperparameters tuning, training process, and so on.\n",
    "\n",
    "- 收集 data 的方式為如果有點選其中一個 item，那就會紀錄這筆點過的資訊並 oversample 2-4 次，其他 4 個 item 則不紀錄，因為這 4 個 item 不一定是 user 不想看的，有可能是因為被點的那個太想看，導致這些 item 沒被選到；如果 user 5 個 item 都不點選，則這 5 個 item 都會記錄下來，因為代表 user 選擇不看的機率比較高，這 5 個 item 是 user 不想看的。\n",
    "\n",
    "- 在和 training 環境互動時，會每隔 500 個 response，就將新蒐集到的資料和原始的資料一起給 model 來 retrain，在 test 環境時則會更頻繁，因為希望多學到新 user 的資料。\n",
    "\n",
    "- 我們有一直在微調 learning rate，不然很多時候會 train 太慢或是一直大震盪，同時也有調整要間隔幾個 response 再去做 retrain。\n",
    "\n",
    "### Discussions, lessons learned, or anything else worth mentioning.\n",
    "\n",
    "- 我認為這次很重要的點就是要超級大量的一直去搜集 training 環境的互動資料，並利用這些曾經點選的紀錄再將來推薦給 user，尤其 training 環境可以無限一直重複跑，所以可以蒐集到無限的資料來準確地建立出每個 user 對每個 item 的喜好，有了這些資料後，甚至不用太厲害的 model 都能輕鬆推薦正確的 item 給 training 環境中的 1000 名 user。\n",
    "\n",
    "- 而 testing 環境中新的 1000 名 user 要準確的推薦給他們實在是太困難了，因為在每次環境中只有短短的時間去得到這些新 user 的 response，然而 item 數量多達 20 萬，要能成功推薦有很大的難度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc3571",
   "metadata": {},
   "source": [
    "## 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b78f50",
   "metadata": {},
   "source": [
    "Overall, through this competition, we found that the key point is to collect more data by interacting with the environment. We mainly tried two different model,  including content-based personal model and collaborative filtering, but we found that their performance are quite similar. Thus, we understood that the model was not the bottleneck. Just before deadline, we finally understood that we should collect as many as possible so our performace started to improve. We used random recommender to interact with the environment and record the data. However, it was a pity that we did’t have enough time to collect more data to pass the TA60 and TA70 at the end. We should have noticed the key point was data earlier:("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
